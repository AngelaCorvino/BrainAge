
[![AngelaCorvino](https://circleci.com/gh/AngelaCorvino/BrainAge.svg?style=shield)](https://app.circleci.com/pipelines/github/AngelaCorvino/BrainAge?branch=main&filter=all)

[![Documentation Status](https://readthedocs.org/projects/brainage/badge/?version=latest)](https://brainage.readthedocs.io/en/latest/?badge=latest)


# BrainAge

This repository belongs to Angela Corvino and Agata Minnocci. It contains our exam project for the course of Computing Methods for Experimental Physics and Data Analysis.

The aim of our project is to implement an algorithm that has the ability to predict brain age analysing features extracted from brain MRIs of a cohort of subjects with Autism Spectrum Disorder and controls. The algorithm will also compare different regression models and evaluate their performance on this task.

## Data

The features are contained in a .csv file in the BrainAge/data folder.
This dataset contains 419 brain morphological features (volumes, thickness, area, etc.) of brain parcels and global measure, computed by means of the [FreeSurfer](https://surfer.nmr.mgh.harvard.edu/) segmentation software for 915 male subjects of the [ABIDE I dataset](http://fcon_1000.projects.nitrc.org/indi/abide/). ABIDE stands for Autism Brain Imaging Data Exchange.
The features were computed by means of the FreeSurfer segmentation software. A subsample of the large amount of features generated by Freesurfer for the ABIDE I data cohort is analyzed.

## Features Selection

Several feature selection techniques can be applied to remove irrelevant, noisy, and redundant features, avoiding overfitting and improving prediction performance, reducing the computational complexity of the learning algorithm, and proving a deeper insight into the data, which highlights which of the features are most informative for age prediction [An Introduction to Variable and Feature Selection](https://www.jmlr.org/papers/volume3/guyon03a/guyon03a.pdf?ref=driverlayer.com/web)

## Outliers
Various statistical criteria exist for the classification of multivariate outliers , but the majority of them requires the knowledge of the feature distributions (e.g. Mahalanobis’ distance, Cook’s distance), while the distributions of the anatomical brain feature values are not a priori known and are not easily understandable from the data (Ferrari et al.)

One of the most commonly used tools in determining outliers is the Z-score. Z-score is just the number of standard deviations away from the mean that a certain data point is.
It is also possible to use the Interquartile Range to Create Outlier Fences.

## K-fold


When implementing K-fold we want the class distribution in the dataset to be preserved in the training and test splits. This means that if, for example, the ratio of <20 years subjects (class0) to >20 years (class1)subject is 1/3. If we set k=4, then the test sets include three data points from class1 and one data point from class 0. Thus, training sets include three data points from class 0 and nine data points from class 1.
This can be done with Stratified Kfold.
We can also extend the binary concept of classo 0 and 1 to multiclass . In particular we are going to divede the dataset in four class.
## Finding counfounders

For our application, we adapted the autoencoder described in 'S. Hawkins, H. He, G. Williams, R. Baxter, Outlier detection using repli-
 cator neural networks' to our data, building a symmetric, four-linear-layer network with N = 424 (the number of features under examination). The three inner layers have 30, 2 and 30 neurons respectively, their activation functions are a hyperbolic tangent, a step-wise function and a hyperbolic tangent again. The fourth layer generates an output with the same dimensions as the input and a sigmoid filter maps the output into the final vector. We trained the autoencoder comparing the output vector with the input features using the Mean Squared Error (MSE) as the loss function.
 
## Data Harmonization 


To mitigate the effect of the different acquisition sites on the features, we have to harmonize data across sites. 

We define harmonization as the explicit removal of site-related effects in multi-site data (cit [Pomponio](https://www.sciencedirect.com/science/article/pii/S1053811919310419?via%3Dihub#!))




For the removal of site effects, different harmonization procedures were compared:
(i) absence of harmonization ;
(ii) removal of site effects using ComBat with age as biological covariate of interest (age covariate);
(iii) removal of site effects using ComBat without specifying (preserving) the age as a biological covariate 
(iv) removal of site effects using neuroHarmonize  specifying the age as a biological covariate.

Why do we have to use the age as covariate ?
We have to consider the interaction between the site variable and the age of the subjects.
If some sites only include subjects with age in specific ranges( this is our case) , it is therefore important to ensure that the harmonization of the site effect does not affect the age-related biological variability of the dataset.


the Combat model we are going to use has been implemented in python by [Fortin et al.](https://www.sciencedirect.com/science/article/abs/pii/S105381191730931X)

The neuroHarmonize model provides similar functionality respect to Combat but has  additional features:

-Separate train/test datasets.
-Specify covariates with generic nonlinear effects. Implemented using Generalized Additive Models (GAMs) from the statsmodels package.
-Skip the empirical Bayes (EB) step of ComBat, if desired.

## Requirements

To use our Python codes the following packages are needed: numpy, scikit-learn, seaborn, pandas, matplotlib, scipy, neuroHarmonize  and  neuroCombat.
## How to use

#Step1 : Clone
Clone the directory 

#Step2 : Main
Run the Python code Modelcomparison.py to
- peform data preprocessing ( self normalization and data harmonization ) 
- predic the age of healthy subjects comparing different regression models
- predict the age of healty subjects using a neuraò network.
-
#Steo 3: Autistic Subjects
Run the python code to
- use the best performing model to predict the age of ustistic subjects
